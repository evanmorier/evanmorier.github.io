<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Polling</title>
    <meta charset="utf-8" />
    <meta name="author" content="Evan Morier" />
    <link href="libs/xaringanExtra-extra-styles-0.2.3.9000/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <link href="libs/panelset-0.2.3.9000/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.3.9000/panelset.js"></script>
    <link href="libs/animate.css-xaringan-3.7.2/animate.fade.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Polling
### Evan Morier
### PS 270: Understanding Political Numbers
### October 2020

---


class: middle

# Before we begin...

Packages I'll be using:


```r
library(tidyverse)
library(infer)
library(janitor)
```






---
class: middle

## Dewey Defeats Truman

.pull-left[
In the 1948 election, newspapers called the race for Dewey based on polling showing him well ahead of Truman

But, Truman ended up winning

Why were the polls so wrong?
]

.pull-right[
&lt;img src="img/dewey.jpg" width="95%" /&gt;
]



---
class: middle

## Importance of Random Sampling

For a poll to be a reliable indicator of public opinion, everyone in the target population must have an equal chance of being polled

In 1948, pollsters used **quota sampling**, where interviewers got to choose anyone they wanted so long as they met certain demographic quotas

- Non-probability sampling method, introduces bias


---
class: middle

## Trump's job approval in a recent poll
 
.left-c[
&lt;br&gt;
A recent poll conducted by NBC News and the Wall Street Journal found that 43% of Americans approve of President Trump's overall job performance

The poll surveyed 800 Americans via live telephone interviews

.footnote[ 
[More results from the poll](https://assets.documentcloud.org/documents/7221894/200781-NBCWSJ-October-Post-Debate-Poll-1b.pdf)
]
]

.right-c[
![](img/nbc-wsj.png)
]


---
class: top, left

# Uncertainty

**Margin of error**: Distance, in percentage points, from the point estimate to either the upper or lower confidence interval

- MOE is half the length of the 95% confidence interval

--

**Example**

In the NBC News/Wall St. Journal poll with 800 respondents the stated margin of error was +/- 3.46 percentage points

This implies that if the poll were re-run many times, 95% of the time Trump's approval rating would be between 39.5% and 46.5%.


---
class: middle

## NBC News/Wall St. Journal poll data

Let's create a data set that represents the respondents polled in the NBC News/Wall St. Journal poll


```r
approval_data &lt;- tibble(
  approve_trump = c(rep("Approve", 344), 
                    rep("Dissaprove/No Opinion", 456))
)

approval_data %&gt;% 
  tabyl(approve_trump)
```

```
##          approve_trump   n percent
##                Approve 344    0.43
##  Dissaprove/No Opinion 456    0.57
```

.footnote[
Note: Just 2 percent of respondents had no opinion
]

---
class: middle

# Calculate Margin of Error and CI


```r
set.seed(608)

approval_sims &lt;- approval_data %&gt;% 
  specify(response = approve_trump, success = "Approve") %&gt;% 
  generate(reps = 1000)

approval_calcs &lt;- approval_sims %&gt;% 
  calculate(stat = "prop") %&gt;% 
  get_confidence_interval(level = 0.95, type = "percentile") %&gt;% 
  mutate(moe = (upper_ci - lower_ci) / 2)

approval_calcs
```

```
## # A tibble: 1 x 3
##   lower_ci upper_ci   moe
##      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;
## 1    0.394    0.464 0.035
```



---
class: middle

# Formula-Based Margin of Error 

Shortcut MOE Formula:

`$$1.96 \times \sqrt{\frac{p(1-p)}{n}}$$`

Example:

`$$1.96 \times \sqrt{\frac{.5(1-.5)}{5000}} = .0139$$`

So we'd say the margin of error is 1.4

Note: MOE is always highest for proportions near .5


---
class: middle

# Beware the Difference in Proportions

A poll's MOE is almost always stated for a single proportion

But we often care about the *difference* in proportions in a poll

- E.g. Trump vs. Biden

The MOE for the difference between two proportions is not the same as the overall poll's MOE

&lt;!-- If you want to know whether one candidate actually has a statistically significant lead over another, you can't just see whether the difference between their respective numbers is greater than twice a poll's margin of error --&gt;


---
class: middle

# Two-Candidate Horse Race

Example: Is Biden ahead of Trump?

The NBC News/Wall St. Journal poll found that 53% of respondents supported Biden vs 39% for Trump

Biden is 14 percentage points ahead of Trump, and the poll's MOE is 3.5

Conventional wisdom says Biden is ahead of Trump

But is this the right conclusion to draw?


---
class: middle

# Getting the Data Ready

Putting the data for Biden vs. Trump into R


```r
biden_trump_data &lt;- tibble(
  pres_vote = c(rep("Biden", 424), rep("Trump", 312), rep("Other/Undec", 64)),
  one = 1 # not impt, just to get infer to work later
)

biden_trump_data %&gt;% 
  tabyl(pres_vote)
```

```
##    pres_vote   n percent
##        Biden 424    0.53
##  Other/Undec  64    0.08
##        Trump 312    0.39
```



---
class: middle

## MOE of Difference in Proportions


```r
set.seed(608)

biden_trump_sims &lt;- biden_trump_data %&gt;% 
  specify(formula = one ~ pres_vote) %&gt;% # ignore "one"
  generate(reps = 1000)

biden_trump_diffs &lt;- biden_trump_sims %&gt;% 
  group_by(replicate) %&gt;% 
  summarise(biden = sum(pres_vote == "Biden") / n(),
            trump = sum(pres_vote == "Trump") / n(),
            biden_lead = biden - trump)

moe_diff &lt;- 1.96 * sd(biden_trump_diffs$biden_lead) * 100
moe_diff
```

```
## [1] 6.556809
```


---
class: middle

# Biden vs. Trump MOE

So the margin of error for the difference between Biden and Trump support is about 6.6 percentage points

- Estimate of 7 using the MOE for the overall poll

Actual difference observed was 14, which is greater than the MOE for the difference, so the difference in support is probably not zero (i.e. Biden is ahead)


---
class: middle

# Formula for MOE for Diff in Props

`$$1.96 \times \sqrt{\frac{(p_{1} + p_{2}) - (p_{1} - p_{2})^2}{n-1}}$$`

In R:


```r
1.96 * sqrt(((.53 + .39) - (.53-.39)^2) / 800)
```

```
## [1] 0.06575501
```


---
class: top, left

# MOE for subgroups is much larger!

A poll's stated margin of error applies to the overall sample, not smaller subgroups (e.g. men, women, white people, black people, etc.)

--

### Marquette Law School poll of Wisconsin

32% of registered voters 18-29 approve of Trump's job performance

- But, only 119 of these young voters were surveyed

`$$1.96 \times \sqrt{\frac{.32(1-.32)}{119}} = .084$$`

MOE is 8.4, over twice as large as the overall MOE (4)


---
class: middle, inverse

# The MOE isn't Everything

There are many sources of error, or inaccuracy, in polls that do not come from the sampling process


---
class: middle

# Unrepresentative Samples

Even if everyone in the target population had an equal chance of being polled, the actual sample might differ from the population 

- Proportions of different demographic groups

This can be fixed, to some extent


---
class: middle

## Making a sample more representative by weighting

Some adjustments can be made to make the results more accurate when, by chance, certain types of people were over or undersampled

Those who were .black-bold[overrepresented] in the poll compared to their share of the population are .black-bold[downweighted]

Those who were **underrepresented** are given **more weight**

Need to know the proportion of different groups in the population


---
class: middle

## Other sources of error

**Sample frame error**: Not everyone in population was a potential respondent

**Non-response bias**: The people who *responded* to the survey (picked up the phone and agreed to take it, opted into an online pane, etc.) are different in *important* ways from those who did not

**Social Desirability Bias**: Respondents do not want to admit supporting a controversial candidate

- Related to the **Bradley Effect**, where respondents profess support for a non-white candidate but in reality will not vote for them

**Survey design**


---
class: middle, inverse, center

# Aggregating and Forecasting

---
class: middle

## Dealing with sampling error in polls

**Aggregating** or averaging many polls helps with sampling error

But pollster .black-bold[herding] can occur, making polls seem more certain than they actually are


---
class: middle

## Poll weights

Some pollsters tend to always show the Democrat/Republican ahead by a certain amount

- When aggregating, polls can be adjusted according to these **house effects**

Polls with stronger methodological approaches can be given more weight

More recent polls and more accurate pollsters also given more weight



---
class: middle

## Forecasting the US presidential election

Popular vote winner doesn't win, electoral college winner does

To forecast EC winner, need to forecast winner of every state + DC

Common to add "fundamentals", e.g. economic indicators, to forecasting models

State polls combined with fundamentals, national polls, and other information to predict each state's winner

Add all the EC votes for states Biden predicted to win to get his predicted EC vote total

Quantify uncertainty by running thousands of simulations

---
class: middle

# Closing thoughts

### Recommended forecasts

Two of the best known and most highly regarded forecasts are those of [FiveThirtyEight](https://projects.fivethirtyeight.com/2020-election-forecast/) and [The Economist](https://projects.economist.com/us-2020-forecast/president).

### Important to keep in mind: unlikely outcomes happen!

- 2016 Trump won unexpectedly

So when forecasts give a probability of 10 or 20 percent to an event, it is not an impossibility
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
